# -*- coding: utf-8 -*-
"""Breast Cancer Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QPjuj3_-w2qdBJUNK2RJVrpijnOKUY_m

### **Setup**
"""

!which python

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# Standard imports
import os

# Third-party imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets

# Local imports
# None

sns.set()

"""Load data

Using scikit-learn's built-in dataset.
"""

datasets.load_breast_cancer
# Binary classification: 2 classes

data = datasets.load_breast_cancer()

data.keys()

print(data["DESCR"])
# Attributes = features

data["data"][:10]

data["feature_names"]

data["target"]

data["target_names"]

"""### **Problem Statement:**

Predict type of tumor based on:

mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error,
fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, worst fractal dimension to predict if a tumor is a benign or malignant tumor.

This is a binary classification problem.
"""

df = pd.DataFrame(data["data"], columns=data["feature_names"])

df["target"] = data["target"]

df.head()

"""### **Basic descriptive statistics**"""

df.describe()

"""### **Distributions of features and target**"""

def feature_distr(col):
  df[col].hist()
  plt.suptitle(col)
  plt.show()

for feature in data["feature_names"]:
  feature_distr(feature)

"""### **Relationship of the data features with the target**"""

df["target"]

# Create a mapping from the numerical target to the actual species names
target_map = dict(enumerate(data["target_names"]))

# Add a new column 'target_name' to the DataFrame using this mapping
df["target_name"] = df["target"].map(target_map)

# Display the first few rows of the DataFrame to confirm the new column
df.head()

# Alternative method
df["target_name"] = df["target"].map({0: "malignant", 1: "benign"})
df.head()

def feat_w_targ(col):
  sns.relplot(x=col, y="target", hue="target_name", data=df)
  plt.suptitle(col, y=1.05)
  plt.show()

for feature in data["feature_names"]:
  feat_w_targ(feature)

"""### **Exploratory Data Analysis EDA - Pairplots**"""

sns.pairplot(df, hue="target_name")

"""# **Train test split**"""

from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df, test_size=0.25)

df_train.shape
# (rows, columns)

df_test.shape

df_train.head()

"""###**Prepare our data for modeling**

This involves splitting the data back into plain NumPy arrays.
"""

X_train = df_train.drop(columns=["target", "target_name"]).values
# drop() method returns a new object and doesn't change the object unless the inplace parameter is set to True
y_train = df_train["target"].values

"""### **Baseline Model:**

If the baseline moel is randomly guessing whether the tumor is benign for every data point, there would be a model accuracy of about 62.7%, or if the model randomly guesses whether the tumor is malignant for every data point, there would be a model accuracy of 37.3%.

### **Modeling - K-Nearest Neighbors**
"""

from sklearn.neighbors import KNeighborsClassifier

"""### **Using a validation set to evaluate our model**"""

model = KNeighborsClassifier()

# Xt stands for "X_train" and Xv stands for "X_validation"
Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.25)

model.fit(Xt, yt)

y_pred = model.predict(Xv)

np.mean(y_pred == yv)

model.score(Xv, yv)

"""### **Using cross-validation to evaluate our model**"""

from sklearn.model_selection import cross_val_score, cross_val_predict

model = KNeighborsClassifier()

accuracies = cross_val_score(model, X_train, y_train)

np.mean(accuracies)

"""### **Missclassification Plots**"""

y_pred = cross_val_predict(model, X_train, y_train, cv=5)

pred_corr_mask = y_pred == y_train

df_pred = df_train.copy()

df_pred["correct_prediction"] = pred_corr_mask

df_pred["predictions"] = y_pred

df_pred["prediction_label"] = df_pred["predictions"].map({0: "malignant", 1: "benign"})

df_pred.head()

features = data["feature_names"]

def missclass_points(features):

  for feat_x in range(len((features))):


    for feat_y in range(len((features))):

      if feat_x == feat_y:
        continue

      sns.scatterplot(x=features[feat_x], y=features[feat_y], hue="prediction_label", data=df_pred)

      plt.title(f"{features[feat_x]} vs {features[feat_y]}")
      plt.show()
      plt.close()

missclass_points(features)

def plot_incorrect_predictions(df_predictions, x_axis_feature, y_axis_feature):
  fig, axs = plt.subplots(2, 2, figsize=(10, 10))
  # 2 by 2 grid of graphs (2 rows and 2 columns) is created
  # 10 by 10 for figure size is a good starting place
  axs = axs.flatten()
  # 2 by 2 numpy array to a 1 by 4 numpy array
  sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="prediction_label", data=df_predictions, ax=axs[0])
  sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="target_name", data=df_predictions, ax=axs[1])
  # Repeation
  sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="correct_prediction", data=df_predictions, ax=axs[2])
  axs[3].set_visible(False)

  plt.show()

for feat_x in features:

  for feat_y in features:

    if feat_x == feat_y:

      continue

    plot_incorrect_predictions(df_pred, feat_x, feat_y)

"""### **Model Tuning**

Model tuning is trying to determine the parameters of yor model (these are known as "hyperparameters") that maximize the model performance.
"""

for reg_param in (1, 2, 5, 10, 11, 12, 13, 14, 15):
  print(reg_param)
  model = KNeighborsClassifier(n_neighbors=reg_param)
  accuracies = cross_val_score(model, X_train, y_train)
  print(f"Model accuracy: {np.mean(accuracies) * 100:.2f}%")

# C (default value fo 1) is essentially detemrining how much you want to avoid misclassifying (controsl regularization)
# It is inverse: low C: High regularization --> underfitting -- > simpler model (focuses on broad trends and ignores important relationships)
# High C: Low regularization --> overfitting -- > model may memorize (doesn't focus on idivudal patterns enough so it may perform poorly when it comes to new data)
# There are more sophisticated ways to do this other than guessing: Bayesian hyperparamater optimization --> main go-to

"""### **Final Model**"""

model=KNeighborsClassifier(n_neighbors=12)

"""### **How well does our model do on the Test Set?**"""

X_test = df_test.drop(columns=["target", "target_name"]).values
y_test = df_test["target"].values

"""### **Train our models using our full Training Dataset**"""

model.fit(X_train, y_train)

y_test_pred = model.predict(X_test)

test_set_correctly_classified = y_test_pred == y_test
test_set_accuracy = np.mean(test_set_correctly_classified)

print(f"Test set accuracy: {test_set_accuracy * 100:.2f}")

df_pred_test = df_test.copy()
df_pred_test["correct_prediction"] = test_set_correctly_classified
df_pred_test["predictions"] = y_test_pred
df_pred_test["prediction_label"] = df_pred_test["predictions"].map({0: "maliganant", 1: "benign"})

df_pred_test.head()

for feat_x in features:

  for feat_y in features:

    if feat_x == feat_y:

      continue

    plot_incorrect_predictions(df_pred_test, feat_x, feat_y)

"""### **In Conclusion...**

In conclusion, we acheived a 87% accuracy on the test database using a K-Nearest Neighbors classification model with these paramters:

```
KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto',
leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)[source]
```
"""